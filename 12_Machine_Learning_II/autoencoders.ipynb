{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders en Machine Learning - Parte I\n",
    "\n",
    "Los autoencoders son un tipo de modelo de aprendizaje automático que utiliza **aprendizaje no supervisado** para aprender representaciones codificadas de los datos.\n",
    "\n",
    "Un autoencoder aprende a **comprimir los datos** en una representación de menor dimensión y **luego los reconstruye** de vuelta a su forma original o una forma aproximada.\n",
    "\n",
    "**Según Federico:**\n",
    "\n",
    "Los autoencoders buscan aprender una función que comprime los datos que recibe, reduciéndolos a una representación codificada de dimensión mucho menor, y luego los reconstruye de vuelta a su forma original a una aproximación cercana.\n",
    "\n",
    "Es como tener un dibujo en un lienzo gigante y querer guardarlo en tu bolsillo. El autoencoder verá el dibujo, tomará los puntos más importantes y hará una versión \"en miniatura\" de ese dibujo. Después, cuando se desee volver a ver el dibujo a tamaño real, el autoencoder puede volver a recrearlos con alta precisión a partir de una fórmula que ha utilizado para comprimirlo y descomprimirlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para trabajar con autoencoders, se requiere instalar `tensorflow` (ya que no viene con Anaconda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting tensorflow\n",
      "  Downloading tensorflow-2.17.0-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading grpcio-1.67.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.2.0 (from tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.3.5)\n",
      "Collecting namex (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading optree-0.13.0-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "     ---------------------------------------- 0.0/48.7 kB ? eta -:--:--\n",
      "     ---------------------------------------- 48.7/48.7 kB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\francisco\\anaconda3\\lib\\site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.17.0-cp312-cp312-win_amd64.whl (2.0 kB)\n",
      "Downloading tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl (385.2 MB)\n",
      "   ---------------------------------------- 0.0/385.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/385.2 MB 7.3 MB/s eta 0:00:53\n",
      "   ---------------------------------------- 0.7/385.2 MB 7.4 MB/s eta 0:00:52\n",
      "   ---------------------------------------- 1.3/385.2 MB 9.4 MB/s eta 0:00:41\n",
      "   ---------------------------------------- 2.8/385.2 MB 14.7 MB/s eta 0:00:27\n",
      "   ---------------------------------------- 4.1/385.2 MB 17.6 MB/s eta 0:00:22\n",
      "    --------------------------------------- 5.7/385.2 MB 20.2 MB/s eta 0:00:19\n",
      "    --------------------------------------- 6.5/385.2 MB 20.8 MB/s eta 0:00:19\n",
      "    --------------------------------------- 7.0/385.2 MB 19.5 MB/s eta 0:00:20\n",
      "    --------------------------------------- 8.5/385.2 MB 20.0 MB/s eta 0:00:19\n",
      "    --------------------------------------- 9.1/385.2 MB 20.0 MB/s eta 0:00:19\n",
      "   - -------------------------------------- 10.1/385.2 MB 19.6 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 11.0/385.2 MB 25.2 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 12.1/385.2 MB 22.6 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 13.3/385.2 MB 22.6 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 14.4/385.2 MB 22.5 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 15.7/385.2 MB 22.6 MB/s eta 0:00:17\n",
      "   - -------------------------------------- 17.4/385.2 MB 25.2 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 19.1/385.2 MB 26.2 MB/s eta 0:00:14\n",
      "   -- ------------------------------------- 20.7/385.2 MB 29.7 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 21.9/385.2 MB 29.7 MB/s eta 0:00:13\n",
      "   -- ------------------------------------- 23.6/385.2 MB 34.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 24.8/385.2 MB 32.7 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 26.7/385.2 MB 34.4 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 28.2/385.2 MB 32.8 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 29.9/385.2 MB 34.4 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 30.9/385.2 MB 32.7 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 32.8/385.2 MB 32.8 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 34.7/385.2 MB 34.4 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 36.5/385.2 MB 36.4 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 38.3/385.2 MB 34.4 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 39.7/385.2 MB 36.4 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 41.2/385.2 MB 36.4 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 42.6/385.2 MB 36.3 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 44.1/385.2 MB 34.4 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 45.7/385.2 MB 34.6 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 46.9/385.2 MB 34.4 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 48.7/385.2 MB 34.4 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 50.4/385.2 MB 34.4 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 52.3/385.2 MB 34.4 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 53.9/385.2 MB 36.4 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 55.4/385.2 MB 34.4 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 56.9/385.2 MB 34.4 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 58.9/385.2 MB 36.4 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 60.8/385.2 MB 36.4 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 62.2/385.2 MB 36.4 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 64.1/385.2 MB 36.4 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 65.9/385.2 MB 38.5 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 67.8/385.2 MB 38.5 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 69.4/385.2 MB 36.3 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 71.1/385.2 MB 36.3 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 72.9/385.2 MB 38.6 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 74.9/385.2 MB 38.6 MB/s eta 0:00:09\n",
      "   ------- -------------------------------- 76.4/385.2 MB 38.5 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 77.1/385.2 MB 32.8 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 78.7/385.2 MB 32.7 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 80.5/385.2 MB 34.4 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 82.1/385.2 MB 34.4 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 83.8/385.2 MB 34.4 MB/s eta 0:00:09\n",
      "   -------- ------------------------------- 85.6/385.2 MB 34.4 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 87.0/385.2 MB 36.3 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 87.6/385.2 MB 32.7 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 89.8/385.2 MB 34.6 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 90.9/385.2 MB 34.4 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 92.2/385.2 MB 31.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 94.0/385.2 MB 31.2 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 95.7/385.2 MB 31.2 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 97.0/385.2 MB 32.8 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 98.0/385.2 MB 32.7 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 99.9/385.2 MB 31.1 MB/s eta 0:00:10\n",
      "   ---------- ---------------------------- 101.7/385.2 MB 34.6 MB/s eta 0:00:09\n",
      "   ---------- ---------------------------- 104.0/385.2 MB 36.4 MB/s eta 0:00:08\n",
      "   ---------- ---------------------------- 106.2/385.2 MB 36.4 MB/s eta 0:00:08\n",
      "   ---------- ---------------------------- 108.1/385.2 MB 43.7 MB/s eta 0:00:07\n",
      "   ----------- --------------------------- 109.8/385.2 MB 40.9 MB/s eta 0:00:07\n",
      "   ----------- --------------------------- 112.0/385.2 MB 43.5 MB/s eta 0:00:07\n",
      "   ----------- --------------------------- 114.2/385.2 MB 43.5 MB/s eta 0:00:07\n",
      "   ----------- --------------------------- 116.3/385.2 MB 40.9 MB/s eta 0:00:07\n",
      "   ----------- --------------------------- 118.0/385.2 MB 40.9 MB/s eta 0:00:07\n",
      "   ------------ -------------------------- 120.2/385.2 MB 43.7 MB/s eta 0:00:07\n",
      "   ------------ -------------------------- 121.5/385.2 MB 43.5 MB/s eta 0:00:07\n",
      "   ------------ -------------------------- 124.2/385.2 MB 43.7 MB/s eta 0:00:06\n",
      "   ------------ -------------------------- 125.7/385.2 MB 40.9 MB/s eta 0:00:07\n",
      "   ------------ -------------------------- 127.9/385.2 MB 43.7 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 129.9/385.2 MB 43.7 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 132.2/385.2 MB 46.7 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 134.1/385.2 MB 43.5 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 136.0/385.2 MB 46.7 MB/s eta 0:00:06\n",
      "   ------------- ------------------------- 138.1/385.2 MB 43.5 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 140.3/385.2 MB 46.9 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 141.4/385.2 MB 43.5 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 143.5/385.2 MB 40.9 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 145.5/385.2 MB 40.9 MB/s eta 0:00:06\n",
      "   -------------- ------------------------ 147.2/385.2 MB 38.5 MB/s eta 0:00:07\n",
      "   -------------- ------------------------ 147.9/385.2 MB 38.5 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 149.8/385.2 MB 34.4 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 151.4/385.2 MB 34.4 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 153.5/385.2 MB 36.4 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 155.8/385.2 MB 36.4 MB/s eta 0:00:07\n",
      "   --------------- ----------------------- 156.5/385.2 MB 32.8 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 158.5/385.2 MB 38.5 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 160.8/385.2 MB 40.9 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 163.0/385.2 MB 40.9 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 164.8/385.2 MB 38.5 MB/s eta 0:00:06\n",
      "   ---------------- ---------------------- 166.5/385.2 MB 38.5 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 168.7/385.2 MB 46.7 MB/s eta 0:00:05\n",
      "   ----------------- --------------------- 170.4/385.2 MB 43.5 MB/s eta 0:00:05\n",
      "   ----------------- --------------------- 172.1/385.2 MB 40.9 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 173.3/385.2 MB 40.9 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 174.4/385.2 MB 36.4 MB/s eta 0:00:06\n",
      "   ----------------- --------------------- 175.7/385.2 MB 34.4 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 177.8/385.2 MB 34.4 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 179.0/385.2 MB 31.2 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 180.9/385.2 MB 32.7 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 183.0/385.2 MB 32.7 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 184.9/385.2 MB 38.5 MB/s eta 0:00:06\n",
      "   ------------------ -------------------- 187.1/385.2 MB 40.9 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 188.9/385.2 MB 40.9 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 191.3/385.2 MB 43.7 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 192.8/385.2 MB 43.7 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 195.0/385.2 MB 43.7 MB/s eta 0:00:05\n",
      "   ------------------- ------------------- 197.2/385.2 MB 43.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 198.6/385.2 MB 43.7 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 200.2/385.2 MB 38.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 201.4/385.2 MB 38.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 203.1/385.2 MB 36.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 205.3/385.2 MB 38.5 MB/s eta 0:00:05\n",
      "   -------------------- ------------------ 207.3/385.2 MB 38.6 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 209.4/385.2 MB 40.9 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 210.4/385.2 MB 36.4 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 212.1/385.2 MB 38.5 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 213.9/385.2 MB 40.9 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 213.9/385.2 MB 40.9 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 215.0/385.2 MB 31.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 216.8/385.2 MB 29.7 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 219.0/385.2 MB 31.2 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 220.8/385.2 MB 32.8 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 222.7/385.2 MB 32.8 MB/s eta 0:00:05\n",
      "   ---------------------- ---------------- 224.8/385.2 MB 40.9 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 226.5/385.2 MB 40.9 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 228.7/385.2 MB 43.7 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 228.8/385.2 MB 40.9 MB/s eta 0:00:04\n",
      "   ----------------------- --------------- 228.9/385.2 MB 31.2 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 229.0/385.2 MB 27.3 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 229.1/385.2 MB 25.1 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 229.3/385.2 MB 22.5 MB/s eta 0:00:07\n",
      "   ----------------------- --------------- 230.0/385.2 MB 21.1 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 231.5/385.2 MB 21.1 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 233.6/385.2 MB 21.1 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 235.4/385.2 MB 21.1 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 235.9/385.2 MB 20.5 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 235.9/385.2 MB 20.5 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 237.5/385.2 MB 17.2 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 239.2/385.2 MB 23.4 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 240.7/385.2 MB 27.3 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 243.3/385.2 MB 29.7 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 245.2/385.2 MB 29.7 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 247.2/385.2 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 248.9/385.2 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 250.6/385.2 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 252.4/385.2 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 254.5/385.2 MB 40.9 MB/s eta 0:00:04\n",
      "   ------------------------- ------------- 256.2/385.2 MB 40.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 258.2/385.2 MB 40.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 259.7/385.2 MB 40.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 261.6/385.2 MB 40.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 263.5/385.2 MB 38.5 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 265.8/385.2 MB 40.9 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 268.0/385.2 MB 40.9 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 269.8/385.2 MB 40.9 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 271.5/385.2 MB 40.9 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 273.7/385.2 MB 40.9 MB/s eta 0:00:03\n",
      "   --------------------------- ----------- 275.8/385.2 MB 40.9 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 277.7/385.2 MB 43.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 279.5/385.2 MB 43.5 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 281.7/385.2 MB 43.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 283.8/385.2 MB 43.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ---------- 285.7/385.2 MB 43.7 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 287.5/385.2 MB 40.9 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 288.8/385.2 MB 43.7 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 290.4/385.2 MB 38.5 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 292.3/385.2 MB 38.5 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 294.1/385.2 MB 38.5 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 295.9/385.2 MB 36.4 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 296.0/385.2 MB 34.4 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 296.4/385.2 MB 28.5 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 297.6/385.2 MB 27.3 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 299.0/385.2 MB 26.2 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 301.3/385.2 MB 28.4 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 303.0/385.2 MB 28.4 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 305.0/385.2 MB 28.4 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 307.0/385.2 MB 38.6 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 308.5/385.2 MB 38.6 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 309.0/385.2 MB 38.5 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 311.0/385.2 MB 34.4 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 313.0/385.2 MB 34.4 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 314.6/385.2 MB 34.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 317.1/385.2 MB 36.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 318.8/385.2 MB 38.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 320.7/385.2 MB 43.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 323.0/385.2 MB 40.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 323.2/385.2 MB 40.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 323.3/385.2 MB 36.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 323.4/385.2 MB 29.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 323.6/385.2 MB 26.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 324.5/385.2 MB 24.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 327.2/385.2 MB 24.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 329.2/385.2 MB 25.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 331.1/385.2 MB 25.1 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 333.5/385.2 MB 29.7 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 334.7/385.2 MB 43.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 336.5/385.2 MB 40.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 338.1/385.2 MB 40.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 340.0/385.2 MB 38.5 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 341.2/385.2 MB 36.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 343.4/385.2 MB 36.4 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 345.4/385.2 MB 38.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 347.0/385.2 MB 38.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 348.3/385.2 MB 38.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 350.9/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 352.9/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 354.8/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 356.1/385.2 MB 38.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 358.3/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 360.4/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 361.8/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 361.9/385.2 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 363.8/385.2 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 365.9/385.2 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 367.7/385.2 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 369.8/385.2 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 371.4/385.2 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 373.6/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.8/385.2 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  378.0/385.2 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  379.6/385.2 MB 43.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  381.5/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  383.3/385.2 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  385.1/385.2 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 385.2/385.2 MB 5.3 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.7/133.7 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.5/57.5 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.67.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 2.1/4.3 MB 44.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 3.6/4.3 MB 38.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 39.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 25.3 MB/s eta 0:00:00\n",
      "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.2/1.2 MB 73.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 18.7 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.3/26.4 MB 48.4 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 4.4/26.4 MB 46.2 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 6.7/26.4 MB 47.8 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 9.0/26.4 MB 47.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 10.3/26.4 MB 43.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 13.3/26.4 MB 46.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 14.3/26.4 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 16.1/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 18.2/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 20.1/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.7/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.9/26.4 MB 38.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 25.5/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 40.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 11.3 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "   ---------------------------------------- 0.0/127.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 127.5/127.5 kB 7.3 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.9/71.9 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 1.5/5.5 MB 47.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.2/5.5 MB 40.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.2/5.5 MB 41.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 38.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 25.1 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp312-cp312-win_amd64.whl (283 kB)\n",
      "   ---------------------------------------- 0.0/283.5 kB ? eta -:--:--\n",
      "   --------------------------------------  276.5/283.5 kB 17.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 283.5/283.5 kB 5.8 MB/s eta 0:00:00\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.67.0 keras-3.6.0 libclang-18.1.1 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.13.0 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 tensorflow-intel-2.17.0 termcolor-2.5.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instalar TensorFlow\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "# Checar instalación\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es sólo una vez (no es necesario reinstalar).\n",
    "\n",
    "Ahora sí, volvamos a los autoencoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[ 0.,  0.,  5., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2., ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10., ..., 12.,  1.,  0.]]),\n",
       " 'target': array([0, 1, 2, ..., 8, 9, 8]),\n",
       " 'frame': None,\n",
       " 'feature_names': ['pixel_0_0',\n",
       "  'pixel_0_1',\n",
       "  'pixel_0_2',\n",
       "  'pixel_0_3',\n",
       "  'pixel_0_4',\n",
       "  'pixel_0_5',\n",
       "  'pixel_0_6',\n",
       "  'pixel_0_7',\n",
       "  'pixel_1_0',\n",
       "  'pixel_1_1',\n",
       "  'pixel_1_2',\n",
       "  'pixel_1_3',\n",
       "  'pixel_1_4',\n",
       "  'pixel_1_5',\n",
       "  'pixel_1_6',\n",
       "  'pixel_1_7',\n",
       "  'pixel_2_0',\n",
       "  'pixel_2_1',\n",
       "  'pixel_2_2',\n",
       "  'pixel_2_3',\n",
       "  'pixel_2_4',\n",
       "  'pixel_2_5',\n",
       "  'pixel_2_6',\n",
       "  'pixel_2_7',\n",
       "  'pixel_3_0',\n",
       "  'pixel_3_1',\n",
       "  'pixel_3_2',\n",
       "  'pixel_3_3',\n",
       "  'pixel_3_4',\n",
       "  'pixel_3_5',\n",
       "  'pixel_3_6',\n",
       "  'pixel_3_7',\n",
       "  'pixel_4_0',\n",
       "  'pixel_4_1',\n",
       "  'pixel_4_2',\n",
       "  'pixel_4_3',\n",
       "  'pixel_4_4',\n",
       "  'pixel_4_5',\n",
       "  'pixel_4_6',\n",
       "  'pixel_4_7',\n",
       "  'pixel_5_0',\n",
       "  'pixel_5_1',\n",
       "  'pixel_5_2',\n",
       "  'pixel_5_3',\n",
       "  'pixel_5_4',\n",
       "  'pixel_5_5',\n",
       "  'pixel_5_6',\n",
       "  'pixel_5_7',\n",
       "  'pixel_6_0',\n",
       "  'pixel_6_1',\n",
       "  'pixel_6_2',\n",
       "  'pixel_6_3',\n",
       "  'pixel_6_4',\n",
       "  'pixel_6_5',\n",
       "  'pixel_6_6',\n",
       "  'pixel_6_7',\n",
       "  'pixel_7_0',\n",
       "  'pixel_7_1',\n",
       "  'pixel_7_2',\n",
       "  'pixel_7_3',\n",
       "  'pixel_7_4',\n",
       "  'pixel_7_5',\n",
       "  'pixel_7_6',\n",
       "  'pixel_7_7'],\n",
       " 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " 'images': array([[[ 0.,  0.,  5., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ..., 15.,  5.,  0.],\n",
       "         [ 0.,  3., 15., ..., 11.,  8.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 11., ..., 12.,  7.,  0.],\n",
       "         [ 0.,  2., 14., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  6., ...,  0.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ...,  5.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ...,  9.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ...,  6.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  1., ...,  6.,  0.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 10.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  0., ..., 12.,  0.,  0.],\n",
       "         [ 0.,  0.,  3., ..., 14.,  0.,  0.],\n",
       "         [ 0.,  0.,  8., ..., 16.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  9., 16., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  3., 13., ..., 11.,  5.,  0.],\n",
       "         [ 0.,  0.,  0., ..., 16.,  9.,  0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.,  0.,  1., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 13., ...,  2.,  1.,  0.],\n",
       "         [ 0.,  0., 16., ..., 16.,  5.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0., 16., ..., 15.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 16.,  0.,  0.],\n",
       "         [ 0.,  0.,  2., ...,  6.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0.,  2., ...,  0.,  0.,  0.],\n",
       "         [ 0.,  0., 14., ..., 15.,  1.,  0.],\n",
       "         [ 0.,  4., 16., ..., 16.,  7.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  0.,  0., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  4., ..., 16.,  2.,  0.],\n",
       "         [ 0.,  0.,  5., ..., 12.,  0.,  0.]],\n",
       " \n",
       "        [[ 0.,  0., 10., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  2., 16., ...,  1.,  0.,  0.],\n",
       "         [ 0.,  0., 15., ..., 15.,  0.,  0.],\n",
       "         ...,\n",
       "         [ 0.,  4., 16., ..., 16.,  6.,  0.],\n",
       "         [ 0.,  8., 16., ..., 16.,  8.,  0.],\n",
       "         [ 0.,  1.,  8., ..., 12.,  1.,  0.]]]),\n",
       " 'DESCR': \".. _digits_dataset:\\n\\nOptical recognition of handwritten digits dataset\\n--------------------------------------------------\\n\\n**Data Set Characteristics:**\\n\\n:Number of Instances: 1797\\n:Number of Attributes: 64\\n:Attribute Information: 8x8 image of integer pixels in the range 0..16.\\n:Missing Attribute Values: None\\n:Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\\n:Date: July; 1998\\n\\nThis is a copy of the test set of the UCI ML hand-written digits datasets\\nhttps://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\\n\\nThe data set contains images of hand-written digits: 10 classes where\\neach class refers to a digit.\\n\\nPreprocessing programs made available by NIST were used to extract\\nnormalized bitmaps of handwritten digits from a preprinted form. From a\\ntotal of 43 people, 30 contributed to the training set and different 13\\nto the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\\n4x4 and the number of on pixels are counted in each block. This generates\\nan input matrix of 8x8 where each element is an integer in the range\\n0..16. This reduces dimensionality and gives invariance to small\\ndistortions.\\n\\nFor info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\\nT. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\\nL. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\\n1994.\\n\\n|details-start|\\n**References**\\n|details-split|\\n\\n- C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\\n  Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\\n  Graduate Studies in Science and Engineering, Bogazici University.\\n- E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\\n- Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\\n  Linear dimensionalityreduction using relevance weighted LDA. School of\\n  Electrical and Electronic Engineering Nanyang Technological University.\\n  2005.\\n- Claudio Gentile. A New Approximate Maximal Margin Classification\\n  Algorithm. NIPS. 2000.\\n\\n|details-end|\\n\"}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos `digits` incluye **imágenes de 8x8 píxeles de dígitos escritos a mano**, utilizadas para entrenar y probar los autoencoders.\n",
    "\n",
    "Para mayor información, revisar la documentación [aquí](https://scikit-learn.org/stable/auto_examples/datasets/plot_digits_last_image.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits['data'][0].reshape(8,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada índice en la clave `data` es una array que contiene 64 elementos. Cada elemento representa un bit en un mapa de bits o matriz de bits (imagen raster) de resolución 8x8 bits, y su valor representa el nivel de claridad. Es decir, son pequeñas imágenes monocromáticas.\n",
    "\n",
    "Representándolo visualmente..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits['data'][0].reshape(8,8), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`plt.imshow` nos permite representar el array en cuestión como mapa de bits.\n",
    "\n",
    "En este caso, se observa una representación del número `0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos otro ejemplo..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits['data'][345].reshape(8,8), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No obstante, `digits` incluye una función para revisar las distintas imágenes de una manera más simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digits.images[4], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Cómo aplicar los autoencoders en este caso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declarar x que contenga todas las imágenes\n",
    "x = digits.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar los datos a un rango de 0 a 1\n",
    "x = x / 16.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA DE FEDERICO:** Típicamente, los números de dígitos tienen valores en el rango de 0 a 16 para cada píxel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1437, 64), (360, 64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test = train_test_split(x, test_size=0.2, random_state=42)\n",
    "x_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir el autoencoder\n",
    "input_image = Input(shape=(64,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA DE FEDERICO:**\n",
    "\n",
    "Con `input_image`, estamos instanciando una nueva capa de entrada que llamamos \"capa tensorial\". Básicamente, es la forma específica que el modelo va a esperar que tenga nuestros datos, y en `shape=(64,)` le estamos diciendo que nuestros arrays de 8x8 van a ser pasados de manera \"aplanada\" en un solo array 1D. Este es nuestro punto de partida para construir un modelo de **red neuronal**.\n",
    "\n",
    "Es decir, todo esto tiene que ver con la **necesidad del modelo** de **cómo va a ver los datos**: nosotros (humanos) preferimos verlos en un mapa de bits de 8x8, pero para el modelo va a ser más fácil verlos en una sola línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = Dense(32, activation='relu')(input_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA DE FEDERICO:**\n",
    "\n",
    "En `encode` se genera una **red neuronal**, o más específicamente, una \"capa densa\", es decir, una capa con muchísimos puntos o nodos de información (de ahí lo \"denso\"), y que todos esos nodos van a estar conectados entre sí, como una red de neuronas, donde cada neurona tiene una conexión directa con cada una de las demás neuronas.\n",
    "\n",
    "El primer parámetro que nos pide `Dense` es el número de nodos (o \"neuronas\"). Federico ha escogido `32` solamente para el caso: no hay un valor fijo o estándar, solo ha estimado la mitad de la cantidad total de pixeles que tiene la imagen.\n",
    "\n",
    "El número a usar en otros casos va a depender de muchos otros factores, de objetos específicos del modelo y del conjunto de datos con los que se esté trabajando, y todo ello puede influir en la capacidad del modelo para aprender patrones complejos de los datos. Por ejemplo:\n",
    "\n",
    "- Si tenemos un **número elevado de nodos**, puede aumentar la capacidad del modelo para **aprender detalles finos** de los datos de entrenamiento (útil para un dataset muy complejo y variado), pero también aumenta el riesgo de que el modelo aprenda \"tanto\" que **aprende incluso el \"ruido\"** de los datos de entrenamiento en lugar de las relaciones importantes generales, perjudicando su rendimiento en datos nuevos.\n",
    "\n",
    "- Si tenemos un **número muy bajo de nodos**, el modelo no podría tener la capacidad suficiente para aprender adecuadamente los patrones de interés en los datos, generando un modelo demasiado simple, **incapaz de capturar la estructura subyacente** de los datos.\n",
    "\n",
    "De ahí que el valor de `32` sea un compromiso entre ambos extremos, para tener una capacidad de aprendizaje razonable en función de las características de los datos de entrada, en este caso en particular.\n",
    "\n",
    "El segundo parámetro, `activation`, especifica la función de activación que se va a utilizar para esta \"capa densa\". Federico ha declarado el valor `'relu'` (que refiere a [\"Rectified Linear Unit\"](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))), que es una de las funciones de activación más comunes en las redes neuronales por su simplicidad y eficacia.\n",
    "\n",
    "El tercer parámetro (que está en sus propios paréntesis) corresponde a los datos de entrada. Es decir, la \"capa densa\" debe aplicarse a los datos de entrada que hemos definido en `input_image`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA PERSONAL:** Para entender esto más gráficamente:\n",
    "\n",
    "![flatten-and-dense-layers-computer-vision-with-keras-p-6-dense-layer-scheme-1024x723.jpg](https://pysource.com/wp-content/uploads/2022/08/flatten-and-dense-layers-computer-vision-with-keras-p-6-dense-layer-scheme-1024x723.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la \"capa densa\", cada nodo recibe los datos de entrada y cada nodo va modificando un poco dichos datos en función de sus propias reglas internas antes de pasarlos al siguiente. Es decir, la red de una \"capa densa\" es como un grupo de personas trabajando juntas procesando \"mensajes\", en donde cada persona puede \"pensar\" el mensaje y contribuir un poco en el procesamiento de esos mensajes de manera diferente, de acuerdo a sus propias características (su propio \"peso\"), transformando el mensaje y llevándolo a la salida de la capa, donde se combinan todos los \"puntos de vista\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir el decodificador\n",
    "decoded = Dense(64, activation='sigmoid')(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable `decoded` es también una \"capa densa\" como `encoded`, pero sus parámetros poseen otros valores:\n",
    "\n",
    "1. Se ha escogido `64` nodos, pues suele ser la misma cantidad de puntos de entrada (en este caso, los 64 pixeles de la imagen original).\n",
    "2. La función de activación `'sigmoid'` convierte los valores de entrada a la capa en valores entre 0 y 1, ya que los datos de entrada también estaban normalizados afín."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoders en Machine Learning - Parte II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto, es donde llamamos al protagonista de esta lección..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_image, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparemos a nuestro `autoencoder` para el entrenamiento, especificando cómo se debería actualizar durante el aprendizaje y cómo se va a medir su rendimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTAS DE FEDERICO:**\n",
    "\n",
    "El optimizador (parámetro `optimizer`) es el que ajusta los pesos del modelo. Concretamente, `'adam'` es uno de los optimizadores más populares y más efectivos, porque ajusta la tasa de aprendizaje automáticamente y funciona muy bien en la mayoría de los casos, sin demasiada configuración.\n",
    "\n",
    "La función de pérdida (parámetro `loss`) mide qué tan bien el modelo está haciendo su trabajo (que, en este caso, es reconstruir la entrada original a partir de la versión comprimida). Concretamente, `'binary_crossentropy'` es una elección muy común cuando los datos de entrada son valores binarios, porque esta función de pérdida compara cada pixel de la imagen de entrada con el pixel correspondiente de la imagen de salida.\n",
    "\n",
    "En resumen, con todo lo anterior, se logran minimizar las diferencias entre la imagen de entrada y la de salida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya estamos listos para el entrenamiento..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 147ms/step - loss: 0.6973 - val_loss: 0.6806\n",
      "Epoch 2/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.6760 - val_loss: 0.6611\n",
      "Epoch 3/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6565 - val_loss: 0.6415\n",
      "Epoch 4/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.6363 - val_loss: 0.6193\n",
      "Epoch 5/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.6131 - val_loss: 0.5937\n",
      "Epoch 6/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5865 - val_loss: 0.5648\n",
      "Epoch 7/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.5567 - val_loss: 0.5346\n",
      "Epoch 8/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.5275 - val_loss: 0.5059\n",
      "Epoch 9/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.4983 - val_loss: 0.4809\n",
      "Epoch 10/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - loss: 0.4747 - val_loss: 0.4609\n",
      "Epoch 11/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - loss: 0.4557 - val_loss: 0.4453\n",
      "Epoch 12/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4406 - val_loss: 0.4333\n",
      "Epoch 13/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.4284 - val_loss: 0.4236\n",
      "Epoch 14/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.4209 - val_loss: 0.4153\n",
      "Epoch 15/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.4121 - val_loss: 0.4082\n",
      "Epoch 16/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4043 - val_loss: 0.4019\n",
      "Epoch 17/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3988 - val_loss: 0.3964\n",
      "Epoch 18/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3936 - val_loss: 0.3915\n",
      "Epoch 19/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3892 - val_loss: 0.3870\n",
      "Epoch 20/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3854 - val_loss: 0.3827\n",
      "Epoch 21/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3802 - val_loss: 0.3787\n",
      "Epoch 22/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3755 - val_loss: 0.3748\n",
      "Epoch 23/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3720 - val_loss: 0.3711\n",
      "Epoch 24/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.3681 - val_loss: 0.3674\n",
      "Epoch 25/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.3646 - val_loss: 0.3639\n",
      "Epoch 26/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.3609 - val_loss: 0.3605\n",
      "Epoch 27/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3570 - val_loss: 0.3571\n",
      "Epoch 28/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - loss: 0.3550 - val_loss: 0.3540\n",
      "Epoch 29/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3505 - val_loss: 0.3509\n",
      "Epoch 30/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3478 - val_loss: 0.3480\n",
      "Epoch 31/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3441 - val_loss: 0.3452\n",
      "Epoch 32/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3416 - val_loss: 0.3425\n",
      "Epoch 33/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3388 - val_loss: 0.3400\n",
      "Epoch 34/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3361 - val_loss: 0.3376\n",
      "Epoch 35/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3349 - val_loss: 0.3352\n",
      "Epoch 36/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3327 - val_loss: 0.3330\n",
      "Epoch 37/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.3291 - val_loss: 0.3309\n",
      "Epoch 38/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3285 - val_loss: 0.3289\n",
      "Epoch 39/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3262 - val_loss: 0.3270\n",
      "Epoch 40/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3235 - val_loss: 0.3251\n",
      "Epoch 41/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3217 - val_loss: 0.3234\n",
      "Epoch 42/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.3208 - val_loss: 0.3217\n",
      "Epoch 43/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.3195 - val_loss: 0.3201\n",
      "Epoch 44/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3162 - val_loss: 0.3185\n",
      "Epoch 45/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3150 - val_loss: 0.3171\n",
      "Epoch 46/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.3132 - val_loss: 0.3157\n",
      "Epoch 47/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3123 - val_loss: 0.3143\n",
      "Epoch 48/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.3115 - val_loss: 0.3130\n",
      "Epoch 49/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.3091 - val_loss: 0.3117\n",
      "Epoch 50/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.3090 - val_loss: 0.3105\n",
      "Epoch 51/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3069 - val_loss: 0.3093\n",
      "Epoch 52/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3058 - val_loss: 0.3081\n",
      "Epoch 53/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.3053 - val_loss: 0.3070\n",
      "Epoch 54/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3038 - val_loss: 0.3059\n",
      "Epoch 55/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.3028 - val_loss: 0.3048\n",
      "Epoch 56/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.3029 - val_loss: 0.3037\n",
      "Epoch 57/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.3006 - val_loss: 0.3027\n",
      "Epoch 58/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.2995 - val_loss: 0.3017\n",
      "Epoch 59/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2987 - val_loss: 0.3007\n",
      "Epoch 60/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2965 - val_loss: 0.2998\n",
      "Epoch 61/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2981 - val_loss: 0.2988\n",
      "Epoch 62/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2963 - val_loss: 0.2978\n",
      "Epoch 63/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2953 - val_loss: 0.2969\n",
      "Epoch 64/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2936 - val_loss: 0.2960\n",
      "Epoch 65/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2929 - val_loss: 0.2951\n",
      "Epoch 66/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2920 - val_loss: 0.2943\n",
      "Epoch 67/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2923 - val_loss: 0.2934\n",
      "Epoch 68/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2908 - val_loss: 0.2925\n",
      "Epoch 69/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2905 - val_loss: 0.2917\n",
      "Epoch 70/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2875 - val_loss: 0.2908\n",
      "Epoch 71/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2883 - val_loss: 0.2901\n",
      "Epoch 72/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.2876 - val_loss: 0.2893\n",
      "Epoch 73/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2858 - val_loss: 0.2885\n",
      "Epoch 74/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.2860 - val_loss: 0.2877\n",
      "Epoch 75/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2848 - val_loss: 0.2869\n",
      "Epoch 76/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2836 - val_loss: 0.2862\n",
      "Epoch 77/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2845 - val_loss: 0.2855\n",
      "Epoch 78/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2835 - val_loss: 0.2847\n",
      "Epoch 79/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2813 - val_loss: 0.2840\n",
      "Epoch 80/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2822 - val_loss: 0.2833\n",
      "Epoch 81/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.2809 - val_loss: 0.2826\n",
      "Epoch 82/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2803 - val_loss: 0.2820\n",
      "Epoch 83/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2790 - val_loss: 0.2813\n",
      "Epoch 84/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2796 - val_loss: 0.2806\n",
      "Epoch 85/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.2786 - val_loss: 0.2800\n",
      "Epoch 86/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2770 - val_loss: 0.2795\n",
      "Epoch 87/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - loss: 0.2772 - val_loss: 0.2788\n",
      "Epoch 88/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - loss: 0.2764 - val_loss: 0.2782\n",
      "Epoch 89/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.2756 - val_loss: 0.2776\n",
      "Epoch 90/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2754 - val_loss: 0.2771\n",
      "Epoch 91/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.2748 - val_loss: 0.2765\n",
      "Epoch 92/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2745 - val_loss: 0.2760\n",
      "Epoch 93/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.2736 - val_loss: 0.2754\n",
      "Epoch 94/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.2731 - val_loss: 0.2750\n",
      "Epoch 95/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.2714 - val_loss: 0.2744\n",
      "Epoch 96/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.2726 - val_loss: 0.2739\n",
      "Epoch 97/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.2717 - val_loss: 0.2734\n",
      "Epoch 98/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.2709 - val_loss: 0.2730\n",
      "Epoch 99/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2698 - val_loss: 0.2725\n",
      "Epoch 100/100\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.2689 - val_loss: 0.2720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d0933d6ff0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(\n",
    "    x_train,\n",
    "    x_train,\n",
    "    epochs=100,      # según Federico, 100 es un punto inicial razonable\n",
    "    batch_size=256,  # según Federico, 256 es un punto inicial razonable\n",
    "    shuffle=True,\n",
    "    validation_data=(x_test, x_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTAS DE FEDERICO:**\n",
    "\n",
    "Parámetros en la función de entrenamiento `fit()`:\n",
    "\n",
    "- Los dos primeros `x_train` representan a los conjuntos de entrada y de salida esperados, respectivamente.\n",
    "\n",
    "- Las épocas (`epoch`) representan el número de veces que va a repasar todo el conjunto de datos de entrenamiento\n",
    "\n",
    "- Durante el entrenamiento, los datos suelen repartirse en lotes, que se procesan de forma independiente. El tamaño del lote (`batch_size`) indica que el modelo debería tomar, para cada lote, la cantidad de muestras asignada en ese parámetro (en este caso, `256` ejemplos de `x_train`). Todas estas muestras son tomadas **a la vez**. El modelo las procesa, ajusta sus pesos y luego repite el proceso con otro lote de la misma cantidad de muestras, etc. El objetivo es maximizar la eficiencia del entrenamiento.\n",
    "\n",
    "- Mezcla (`shuffle`) hace que los datos se reordenen de manera aleatoria **antes de cada época**, lo que **previene que el modelo aprenda el orden específico de los datos** (algo no deseado) en lugar de las características subyacentes de los mismos (lo que sí es deseado) y, por lo tanto, la posibilidad de generalización del modelo a datos nuevos.\n",
    "\n",
    "- En los datos de validación (`validation_data`), se coloca una tupla con los datos de prueba, en este caso, dos veces `x_test`, según lo definido en los dos primeros argumentos. El concepto habla por sí mismo. 😛 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, nuestro modelo ya ha sido entrenado!! 😎\n",
    "\n",
    "Veamos cómo funciona, visualizando nuestros datos, en un bloque de código que tome 10 imágenes del dataset, las muestre cómo son inicialmente, las codifique, las decodifique y finalmente las vuelva a representar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    # Imágenes originales\n",
    "    plt.subplot(\n",
    "        2,     # filas\n",
    "        10,    # columnas\n",
    "        i + 1  # posición de cada plot\n",
    "    )\n",
    "    plt.imshow(x_test[i].reshape(8,8), cmap='gray')\n",
    "\n",
    "    # Imágenes decodificadas\n",
    "    plt.subplot(\n",
    "        2,\n",
    "        10,\n",
    "        i + 1 + 10\n",
    "    )\n",
    "    plt.imshow(autoencoder.predict(x_test)[i].reshape(8,8), cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
