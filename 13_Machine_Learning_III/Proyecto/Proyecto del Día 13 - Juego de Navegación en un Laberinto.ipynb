{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7bf2362",
   "metadata": {},
   "source": [
    "## Proyecto del Día 13 - Juego de Navegación en un Laberinto\n",
    "\n",
    "Este proyecto tiene como objetivo desarrollar un entorno de laberinto simple y aplicar un algoritmo de **Aprendizaje por Refuerzo** para enseñar a una IA a navegar desde un punto inicial hasta un objetivo.\n",
    "\n",
    "Dada la naturaleza de este proyecto, considero que el algoritmo más adecuado para este tipo de probleas es **Q-Learning**, por su facilidad de implelentación y comprensión, su estabilidad y su relación entre la exploración y la explotación.\n",
    "\n",
    "Por esa razón te propongo resolverlo usando ese algoritmo, aunque dejo a tu criterio si quieres resolverlo con otro algoritmo de tu elección. Siempre estaré a favor de que investigues, y expandas las habilidades propuestas por tu cuenta.\n",
    "\n",
    "### Descripción del Laberinto:\n",
    "\n",
    "El laberinto se representa como una matriz de dos dimensiones, donde cada elemento puede ser:\n",
    "+ un camino libre (0)\n",
    "+ un obstáculo (1)\n",
    "+ el objetivo (G)\n",
    "\n",
    "La tarea es desarrollar un agente que pueda aprender a encontrar el camino desde un punto de inicio hasta el objetivo evitando obstáculos.\n",
    "\n",
    "\n",
    "### Creación del Laberinto\n",
    "\n",
    "Debido a que el desafío de hoy es bastante complejo, y que el objetivo final no se trata de que sepas desarrollar laberintos, sino sistemas para resolverlos, voy a facilitar la tarea entregando en este cuaderno el código para generar nuestros laberintos.\n",
    "\n",
    "Tu parte será la siguiente, que es diseñar y entrenar un modelo de Q-Learning para resolver el laberinto de la manera mpas eficiente, y luego mostrar una visualización sobre cómo lo ha hecho.\n",
    "\n",
    "Te deseo toda la suerte del mundo, y sobre todo, que te diviertas de a montones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e7ecc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías necesarias para todo el ejercicio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6370346d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para crear el laberinto\n",
    "def crear_laberinto(tamanio, porcentaje_paredes=20, inicio=(0, 0), meta=None):\n",
    "    laberinto = np.zeros((tamanio, tamanio))\n",
    "    numero_paredes = int((tamanio * tamanio) * porcentaje_paredes / 100)\n",
    "    \n",
    "    # Ubicar paredes\n",
    "    for pared in range(numero_paredes):\n",
    "        x, y = random.randint(0, tamanio-1), random.randint(0, tamanio-1)\n",
    "        \n",
    "        # Cuidar que inicio y meta no sean paredes\n",
    "        if (x, y) != inicio and (meta is None or (x, y) != meta):\n",
    "            laberinto[x, y] = 1\n",
    "            \n",
    "    # Ubicar la meta\n",
    "    if meta:\n",
    "        laberinto[meta] = 9  # Representa la meta con 9\n",
    "    else:\n",
    "        # Ubicar la meta aleatoriamente si no está especificado\n",
    "        while True:\n",
    "            x, y = random.randint(0, tamanio-1), random.randint(0, tamanio-1)\n",
    "            if laberinto[x, y] == 0 and (x, y) != inicio:\n",
    "                laberinto[x, y] = 9\n",
    "                break\n",
    "    \n",
    "    return laberinto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c648cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para visualizar el laberinto\n",
    "def ver_laberinto(laberinto):\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.imshow(laberinto, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10e052cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejemplo de crear y mostrar laberintos\n",
    "laberinto = crear_laberinto(10, 20, inicio=(0, 0), meta=(9, 9))\n",
    "ver_laberinto(laberinto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c75336c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 1., 0., 1., 0.],\n",
       "       [1., 0., 0., 1., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 1., 0., 0., 0., 0., 9.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laberinto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f986ed5",
   "metadata": {},
   "source": [
    "### Ahora te toca a ti\n",
    "\n",
    "Lo que sigue es implementar todo el código para que un algoritmo de Q-Learning encuentre la manera más eficiente de llegar a la meta. Voy a dejarte los pasos que considero que son los necesarios para lograrlo\n",
    "\n",
    "##### 1. Parámetros para el algoritmo Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "234853df",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state: tuple[int, int] = (0, 0)\n",
    "goal_state: tuple[int, int] = (9, 9)\n",
    "\n",
    "up: int = 0\n",
    "down: int = 1\n",
    "left: int = 2\n",
    "right: int = 3\n",
    "\n",
    "actions: dict[int, tuple[int, int]] = {\n",
    "    up: (0, -1),\n",
    "    down: (0, 1),\n",
    "    left: (-1, 0),\n",
    "    right: (1, 0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1291a4f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_states: int = laberinto.shape[0] * laberinto.shape[1]\n",
    "grid_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e36682e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_actions: int = len(actions)\n",
    "possible_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e67461da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_state_to_index(\n",
    "        state: tuple[int, int],\n",
    "        grid: tuple[int, int]\n",
    "        ) -> int:\n",
    "    \"\"\"\n",
    "    Convert the current two-dimensional representation of the current\n",
    "    state (the agent's position on the grid) to an unique linear index.\n",
    "\n",
    "    Every possible state can be represented as a index number for the\n",
    "    Q table.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    state : tuple[int, int]\n",
    "        The current two-dimensional representation of the current state\n",
    "        (the agent's position on the grid).\n",
    "\n",
    "    grid : tuple[int, int]\n",
    "        The width and height of the grid.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        The index of the current state in the Q table.\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> convert_state_to_index((0, 0), (5, 5))\n",
    "    0\n",
    "    >>> convert_state_to_index((4, 4), (5, 5))\n",
    "    24\n",
    "\n",
    "    \"\"\"\n",
    "    return state[0] * grid[1] + state[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da64af62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = laberinto.shape\n",
    "example = convert_state_to_index((9, 9), (x, y))\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f4da219",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha: float = 0.1      # learning rate\n",
    "gamma: float = 0.99     # discount factor\n",
    "epsilon: float = 0.2    # exploration\n",
    "episodes: int = 100     # number of episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125709aa",
   "metadata": {},
   "source": [
    "##### 2. Función para elegir acciones equilibrando entre explotación y exploración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abbd3e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(\n",
    "        Q: np.ndarray,\n",
    "        state: tuple[int, int],\n",
    "        actions: dict[int, tuple[int, int]],\n",
    "        grid: tuple[int, int],\n",
    "        epsilon: float\n",
    "        ) -> int:\n",
    "    \"\"\"\n",
    "    Choose a random action or the best action for the current state,\n",
    "    depending on the exploration rate.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Q : np.ndarray\n",
    "        The Q table.\n",
    "    \n",
    "    state : tuple[int, int]\n",
    "        The current two-dimensional representation of the current state\n",
    "        (the agent's position on the grid).\n",
    "    \n",
    "    actions : dict[int, tuple[int, int]]\n",
    "        The list of possible actions.\n",
    "\n",
    "    grid : tuple[int, int]\n",
    "        The width and height of the grid.\n",
    "\n",
    "    epsilon : float\n",
    "        The exploration rate.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        A random action or the best action for the current state,\n",
    "        depending on the exploration rate.\n",
    "    \n",
    "    Requirements\n",
    "    ------------\n",
    "    1. Python's built-in `random` library (`import random`).\n",
    "    2. NumPy (`import numpy as np`).\n",
    "    3. The `convert_state_to_index()` function declared above.        \n",
    "    \"\"\"\n",
    "    random_number: float = random.uniform(0, 1)\n",
    "    random_action: int = random.choice(list(actions.keys()))\n",
    "    best_action: int = int(np.argmax(Q[convert_state_to_index(state, grid)]))\n",
    "\n",
    "    if random_number < epsilon:\n",
    "        return random_action\n",
    "    return best_action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a6550",
   "metadata": {},
   "source": [
    "##### 3. Función para simular la acción en el laberinto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f719b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_action(\n",
    "        action: int,\n",
    "        state: tuple[int, int],\n",
    "        goal_state: tuple[int, int],\n",
    "        grid: tuple[int, int],\n",
    "        obstacles: list[tuple[int, int]]\n",
    "        ) -> tuple[tuple[int, int], int, bool]:\n",
    "    \"\"\"\n",
    "    Apply the action to the current state.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    action : int\n",
    "        The action to be applied.\n",
    "\n",
    "    state : tuple[int, int]\n",
    "        The current two-dimensional representation of the current state\n",
    "        (the agent's position on the grid).\n",
    "\n",
    "    goal_state : tuple[int, int]\n",
    "        The two-dimensional representation of the state declared as\n",
    "        goal.\n",
    "\n",
    "    grid : tuple[int, int]\n",
    "        The width and height of the grid.\n",
    "\n",
    "    obstacles : list[tuple[int, int]]\n",
    "        The list of obstacles on the grid.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[tuple[int, int], int, bool]\n",
    "        The new state, the reward, and whether the game is over.\n",
    "\n",
    "    \"\"\"\n",
    "    points: int = 0\n",
    "    is_game_over: bool = False\n",
    "\n",
    "    new_state: tuple[int, int] = tuple(np.add(state, action) % grid)\n",
    "\n",
    "    if new_state in obstacles or new_state == state:\n",
    "        points = -100\n",
    "        return state, points, is_game_over\n",
    "    elif new_state == goal_state:\n",
    "        points = 100\n",
    "        is_game_over = True\n",
    "        return new_state, points, is_game_over\n",
    "    else:\n",
    "        points = -1\n",
    "        return new_state, points, is_game_over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c3dc48",
   "metadata": {},
   "source": [
    "##### 4. Función principal para ejecutar el algoritmo Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ee5259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Q_values(\n",
    "        Q: np.ndarray,\n",
    "        state_index: int,\n",
    "        action_index: int,\n",
    "        alpha: float,\n",
    "        gamma: float,\n",
    "        new_state_index: int,\n",
    "        reward: int,\n",
    "        ) -> float:\n",
    "    \"\"\"\n",
    "    Update the Q values for the current state and action.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    Q : np.ndarray\n",
    "        The Q table.\n",
    "\n",
    "    state_index : tuple[int, int]\n",
    "        The index of the current state in the Q table.\n",
    "\n",
    "    action_index : int\n",
    "        The index of the current action in the Q table.\n",
    "\n",
    "    alpha : float\n",
    "        The learning rate.\n",
    "\n",
    "    gamma : float\n",
    "        The discount factor.\n",
    "\n",
    "    new_state_index : tuple[int, int]\n",
    "        The index of the new state in the Q table.\n",
    "\n",
    "    reward : int\n",
    "        The reward for the current state and action.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The updated Q value.\n",
    "    \"\"\"\n",
    "    current_q = Q[state_index, action_index]\n",
    "    best_future_q = np.max(Q[new_state_index])\n",
    "    return current_q + alpha * (reward + (gamma * best_future_q) - current_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac97336",
   "metadata": {},
   "source": [
    "##### 5. Función para convertir coordenadas a índice lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5311d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f60f0d38",
   "metadata": {},
   "source": [
    "##### 6. Iniciar el laberinto y configurar el algoritmo Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2355b8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "addf32a0",
   "metadata": {},
   "source": [
    "##### 7. Función para mostrar el aprendizaje del agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f818e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "060cb8db",
   "metadata": {},
   "source": [
    "##### 8. Visualizar el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f1228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
