{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning en Machine Learning - Parte I (1)\n",
    "Implementa la funci贸n `indice_a_estado`, que toma un 铆ndice lineal (n煤mero entero) y lo convierte de nuevo a una representaci贸n bidimensional (tupla) del estado actual en la cuadr铆cula. Esta funci贸n es la inversa de `estado_a_indice` que vimos en la lecci贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4)\n"
     ]
    }
   ],
   "source": [
    "def indice_a_estado(\n",
    "        indice_lineal: int,\n",
    "        ) -> tuple[int, int]:\n",
    "    estado_0, estado_1 = divmod(indice_lineal, 5)\n",
    "    return estado_0, estado_1\n",
    "\n",
    "\n",
    "print(indice_a_estado(24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA PERSONAL:** Esta es la soluci贸n aceptada en Udemy, pero no me parece que el valor `5` en `divmod()` deba ser hardcoded. Lamentablemente, el ejercicio no pemite pasar un segundo argumento a la funci贸n. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Learning en Machine Learning - Parte I (2)\n",
    "Escribe una funci贸n `crear_entorno()` que inicialice el entorno con las condiciones dadas: **dimensiones de la cuadr铆cula, estado_inicial, estado_objetivo y obst谩culos.**\n",
    "\n",
    "1. Define una cuadr铆cula con dimensiones de 5x5. `dimensiones`\n",
    "\n",
    "2. El punto de inicio est谩 en la esquina superior izquierda (0,0). `estado_inicial`\n",
    "\n",
    "3. El punto objetivo est谩 en la esquina inferior derecha (4,4). `estado_objetivo`\n",
    "\n",
    "4. Obst谩culos distribuidos en: (1,1), (1,3), (2,3), (3,0). `obstaculos`\n",
    "\n",
    "Asegurate que esta funci贸n devuelva todos los valores requeridos:\n",
    "\n",
    "`dimensiones`, `estado_inicial`, `estado_objetivo`, `obstaculos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeAlias\n",
    "\n",
    "\n",
    "EnvironmentType: TypeAlias = tuple[\n",
    "    tuple[int, int],\n",
    "    tuple[int, int],\n",
    "    tuple[int, int],\n",
    "    list[tuple[int, int]]\n",
    "]\n",
    "\n",
    "\n",
    "def crear_entorno() -> EnvironmentType:\n",
    "    dimensiones: tuple[int, int] = (5, 5)\n",
    "    estado_inicial: tuple[int, int] = (0, 0)\n",
    "    estado_objetivo: tuple[int, int] = (4, 4)\n",
    "    obstaculos: list[tuple[int, int]] = [(1, 1), (1, 3), (2, 3), (3, 0)]\n",
    "    return dimensiones, estado_inicial, estado_objetivo, obstaculos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q - Learning en Machine Learning - Parte II (1)\n",
    "\n",
    "En este ejercicio, desarrollar谩s una funci贸n denominada `elegir_accion`, la cual selecciona una acci贸n basada en la estrategia epsilon-greedy. Esta estrategia es fundamental en el aprendizaje por refuerzo para equilibrar entre la exploraci贸n (seleccionar acciones al azar) y la explotaci贸n (seleccionar la mejor acci贸n conocida).\n",
    "\n",
    "**Datos Iniciales:**\n",
    "\n",
    "Se te proporcionan los siguientes componentes iniciales en Python:\n",
    "\n",
    "- `epsilon`: Un valor flotante que representa la probabilidad de tomar una acci贸n aleatoria. El valor es 0.1.\n",
    "\n",
    "- `num_acciones`: Un entero que indica el n煤mero total de acciones posibles, que en este caso es 4.\n",
    "\n",
    "- `Q`: Una matriz de ceros con dimensiones 25x4 que representa los valores estimados de cada acci贸n en cada estado.\n",
    "\n",
    "- `dimensiones`: Una tupla que indica las dimensiones de un espacio de estados estructurado en forma de cuadr铆cula (5x5).\n",
    "\n",
    "**Funciones Proporcionadas:**\n",
    "\n",
    "- `estado_a_indice(estado)`: Esta funci贸n convierte un estado, representado como una tupla de dos elementos (fila, columna), en un 铆ndice lineal para acceder a la matriz `Q`.\n",
    "\n",
    "### Instrucciones:\n",
    "\n",
    "1. Completa la funci贸n `elegir_accion`:\n",
    "\n",
    "    - **Par谩metro de entrada:** `estado`, una tupla que representa el estado actual en forma de (fila, columna).\n",
    "\n",
    "    - **Valor de retorno:** Debe devolver un entero que representa el 铆ndice de la acci贸n elegida.\n",
    "\n",
    "    - **Comportamiento esperado:**\n",
    "\n",
    "        - Con una probabilidad `epsilon`, la funci贸n debe elegir y retornar una acci贸n de manera aleatoria.\n",
    "\n",
    "        - Con una probabilidad `1 - epsilon`, la funci贸n debe retornar la acci贸n que tiene el mayor valor en la matriz `Q` para el estado dado.\n",
    "\n",
    "2. Utiliza la funci贸n `random.uniform(0, 1)` para generar un n煤mero aleatorio y compararlo con `epsilon` para decidir si se explora o se explota.\n",
    "\n",
    "3. Utiliza `random.choice(range(num_acciones))` para seleccionar una acci贸n aleatoria durante la fase de exploraci贸n.\n",
    "\n",
    "4. Utiliza `np.argmax()` para seleccionar la acci贸n con el mayor valor de `Q` durante la fase de explotaci贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Par谩metros globales para la funci贸n elegir_accion\n",
    "epsilon: float = 0.1\n",
    "num_acciones: int = 4\n",
    "Q: np.ndarray = np.zeros((25, num_acciones))  # Ejemplo de matriz Q\n",
    "dimensiones: tuple[int, int] = (5, 5)\n",
    "\n",
    "def estado_a_indice(estado: tuple[int, int]) -> int:\n",
    "    # Convierte el estado en un 铆ndice para la matriz Q\n",
    "    return estado[0] * dimensiones[1] + estado[1]\n",
    "\n",
    "def elegir_accion(estado: tuple[int, int]) -> int:\n",
    "    # Implementa la estrategia epsilon-greedy\n",
    "    # Exploraci贸n: elige una acci贸n aleatoria\n",
    "    # Explotaci贸n: elige la mejor acci贸n seg煤n la matriz Q\n",
    "    numero_aleatorio: float = random.uniform(0, 1)\n",
    "    accion_aleatoria: int = random.choice(range(num_acciones))\n",
    "    mejor_accion: int = int(np.argmax(Q[estado_a_indice(estado)]))\n",
    "\n",
    "    if numero_aleatorio < epsilon:\n",
    "        return accion_aleatoria\n",
    "    return mejor_accion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q - Learning en Machine Learning - Parte II (2)\n",
    "Implementa una funci贸n llamada `aplicar_accion`. Esta funci贸n ser谩 parte de un sistema de navegaci贸n en un grid donde un agente puede moverse y encontrar un objetivo mientras evita obst谩culos.\n",
    "\n",
    "**Variables de Configuraci贸n:**\n",
    "\n",
    "- `acciones`: Una lista de tuplas que representan las direcciones de movimiento posibles. Estas direcciones son: izquierda, abajo, derecha y arriba.\n",
    "\n",
    "- `dimensiones`: Una tupla que define las dimensiones del grid (5x5).\n",
    "\n",
    "- `obstaculos`: Una lista de tuplas que indica las posiciones de los obst谩culos en el grid.\n",
    "\n",
    "- `estado_objetivo`: Una tupla que se帽ala la posici贸n del objetivo en el grid.\n",
    "\n",
    "```\n",
    "acciones = [(0, -1), (1, 0), (0, 1), (-1, 0)]\n",
    "dimensiones = (5, 5)\n",
    "obstaculos = [(2, 2), (3, 3)]\n",
    "estado_objetivo = (4, 4)\n",
    "```\n",
    "\n",
    "**Objetivo:**\n",
    "\n",
    "Tu tarea es implementar la funci贸n `aplicar_accion` utilizando las variables de configuraci贸n proporcionadas. Debes asegurarte de que la funci贸n maneje correctamente los movimientos hacia los obst谩culos, el movimiento fuera de los l铆mites del grid, y la identificaci贸n cuando el agente alcanza el objetivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Variables de configuraci贸n\n",
    "acciones = [(0, -1), (1, 0), (0, 1), (-1, 0)]  # Movimientos: izquierda, abajo, derecha, arriba\n",
    "dimensiones = (5, 5)  # Dimensiones del grid\n",
    "obstaculos = [(2, 2), (3, 3)]  # Posiciones de obst谩culos\n",
    "estado_objetivo = (4, 4)  # Posici贸n del objetivo\n",
    "\n",
    "def aplicar_accion(estado, accion_idx):\n",
    "    \"\"\"\n",
    "    Aplica una acci贸n basada en un 铆ndice de acci贸n dado y actualiza el estado del agente en el grid.\n",
    "\n",
    "    Par谩metros:\n",
    "    - estado (tuple): La posici贸n actual del agente en el grid.\n",
    "    - accion_idx (int): El 铆ndice de la acci贸n a aplicar, que est谩 basado en la lista 'acciones'.\n",
    "\n",
    "    Retorna:\n",
    "    - tuple: El nuevo estado del agente despu茅s de aplicar la acci贸n.\n",
    "    - int: La recompensa o penalizaci贸n resultante de la acci贸n.\n",
    "    - bool: Un booleano que indica si el objetivo ha sido alcanzado.\n",
    "    \"\"\"\n",
    "    puntos = 0\n",
    "    terminado = False\n",
    "    accion = acciones[accion_idx]\n",
    "    nuevo_estado = (estado[0] + accion[0], estado[1] + accion[1])\n",
    "\n",
    "    if (0 <= nuevo_estado[0] < dimensiones[0]) and (0 <= nuevo_estado[1] < dimensiones[1]):\n",
    "        if nuevo_estado in obstaculos:\n",
    "            puntos = -100\n",
    "            return estado, puntos, terminado\n",
    "        elif nuevo_estado == estado_objetivo:\n",
    "            puntos = 100\n",
    "            terminado = True\n",
    "            return nuevo_estado, puntos, terminado\n",
    "        else:\n",
    "            puntos = -1\n",
    "            return nuevo_estado, puntos, terminado\n",
    "    else:\n",
    "        puntos = -1\n",
    "        return nuevo_estado, puntos, terminado"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
